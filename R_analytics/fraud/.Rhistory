## plot length composition data and fits
plot_LCfits(Inputs=Inputs,
Report=Report,
LBSPR=lbspr_res)
abline(v=lh$linf, lwd=2, lty=2, col="red")
## plot model output
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
LBSPR=lbspr_res,
lh=lh,
true_years=data_list$years,
plot=c("Selex"))
abline(v=lh$linf, lwd=2, lty=2, col="red")
abline(v=Report$ML_ft[length(Report$ML_ft)], lwd=2, lty=2, col="blue")
legend("topleft", legend=c("LIME Selectivity", "LBSPR Selectivity", "Mean length in catch", "Linf"),
col=c("#00AA00", "#AA00AA", "blue", "red"), lty=c(1,1,2,2), lwd=2)
lbspr_res <- LBSPRfit(LB_pars=LB_pars, LB_lengths=LB_lengths, Control=list(modtype=c("GTG")))
## plot model output
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
True=true,
LBSPR=lbspr,
plot=c("Fish"),
set_ylim=list("Fish" =c(0,1), "SPR" = c(0,1), "SB"=c(0,2)))
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
True=true,
LBSPR=lbspr,
plot=c("Fish"))
plot_output(Inputs=Inputs)
## plot model output
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
True=true)
Inputs
lc_only <- run_LIME(modpath=NULL,
input=inputs_LC,
data_avail="LC")
View(lc_only)
## check TMB inputs
Inputs <- lc_only$Inputs
## Report file
Report <- lc_only$Report
## Standard error report
Sdreport <- lc_only$Sdreport
## check convergence
hessian <- Sdreport$pdHess
gradient <- lc_only$opt$max_gradient <= 0.001
hessian == TRUE & gradient == TRUE
# hessian not positive definite -- the following line helps diagnose which
#  parameters can't be estimated
check <- TMBhelper::Check_Identifiable(lc_only$obj)
## issues estimating F - try a more narrow penalty on F
inputs_LC_new <- inputs_LC
inputs_LC_new$SigmaF <- 0.1
lc_only2 <- run_LIME(modpath=NULL,
input=inputs_LC_new,
data_avail="LC")
## check TMB inputs
Inputs <- lc_only2$Inputs
## Report file
Report <- lc_only2$Report
## Standard error report
Sdreport <- lc_only2$Sdreport
## check convergence
hessian <- Sdreport$pdHess
gradient <- lc_only$opt$max_gradient <= 0.001
hessian == TRUE & gradient == TRUE
plot_LCfits(Inputs=Inputs,
Report=Report,
plot_fit=FALSE)
## plot length composition data
plot_LCfits(Inputs=Inputs,
Report=Report,
LBSPR=lbspr)
## plot model output
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
True=true,
LBSPR=lbspr,
plot=c("Fish"),
set_ylim=list("Fish" =c(0,1), "SPR" = c(0,1), "SB"=c(0,2)))
## setup length frequency matrix
lf <- as.matrix(df[,2], nrow=1, ncol=nrow(df))
rownames(lf) <- "2018"
colnames(lf) <- bins
lf <- matrix(df[,2], nrow=1, ncol=nrow(df))
glimpse(lf)
LFlist
## plot model output
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
plot="Selex")
abline(v=lh$linf, lwd=2, lty=2, col="red")
abline(v=Report$ML_ft[length(Report$ML_ft)], lwd=2, lty=2, col="blue")
legend("topleft", legend=c("Selectivity", "Mean length in catch", "Linf"),
col=c("#00AA00", "blue", "red"), lty=c(1,2,2), lwd=2)
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
plot="Selex")
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
plot=c("Fish"))
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
plot="Fish")
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
plot="Fish")
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
plot="Selex")
inputs_all$theta <- 50
check1 <- run_LIME(modpath = NULL, input = inputs_all, data_avail = "LC",
fix_more = "log_theta", C_type = 2)
gradient <- check1$opt$max_gradient <= 0.001
hessian <- check1$Sdreport$pdHess
hessian == TRUE & gradient == TRUE
plot_LCfits(LF_df = LF_df, Inputs = check1$Inputs, Report = check1$Report)
plot_output(Inputs = check1$Inputs, Report = check1$Report, Sdreport = check1$Sdreport,
lh = lh, True = NULL, plot = c("Fish", "Rec", "SPR", "ML", "SB", "Selex"),
set_ylim = list(Fish = c(0, 0.5), SPR = c(0, 1)))
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
True=true,
LBSPR=lbspr,
plot=c("Selex"),
set_ylim=list("Fish" =c(0,1), "SPR" = c(0,1), "SB"=c(0,2)))
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
True=true,
LBSPR=lbspr,
plot=c("ML"),
set_ylim=list("Fish" =c(0,1), "SPR" = c(0,1), "SB"=c(0,2)))
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
True=true,
LBSPR=lbspr,
plot="ML")
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
True=true,
LBSPR=lbspr,
plot="SB")
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
True=true,
LBSPR=lbspr,
plot="SPR")
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
True=true,
LBSPR=lbspr,
plot="Rec")
## plot model output
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
True=true,
LBSPR=lbspr,
plot="Fish")
lc_only <- run_LIME(modpath=NULL,
input=inputs_LC,
data_avail="LC")
## check TMB inputs
Inputs <- lc_only$Inputs
## Report file
Report <- lc_only$Report
## Standard error report
Sdreport <- lc_only$Sdreport
## check convergence
hessian <- Sdreport$pdHess
gradient <- lc_only$opt$max_gradient <= 0.001
hessian == TRUE & gradient == TRUE
## hessian not positive definite -- the following line helps diagnose which parameters can't be estimated
check <- TMBhelper::Check_Identifiable(lc_only$obj)
## issues estimating F - try a more narrow penalty on F
inputs_LC_new <- inputs_LC
inputs_LC_new$SigmaF <- 0.1
lc_only2 <- run_LIME(modpath=NULL,
input=inputs_LC_new,
data_avail="LC")
## check TMB inputs
Inputs <- lc_only2$Inputs
## Report file
Report <- lc_only2$Report
## Standard error report
Sdreport <- lc_only2$Sdreport
## check convergence
hessian <- Sdreport$pdHess
gradient <- lc_only$opt$max_gradient <= 0.001
hessian == TRUE & gradient == TRUE
## LBSPR
LB_pars <- new("LB_pars")
LB_pars@MK <- inputs_all$M/inputs_all$vbk
LB_pars@Linf <- inputs_all$linf
LB_pars@L50 <- inputs_all$ML50
LB_pars@L95 <- inputs_all$ML95
LB_pars@Walpha <- inputs_all$lwa
LB_pars@Wbeta <- inputs_all$lwb
LB_pars@R0 <- inputs_all$R0
LB_pars@Steepness <- ifelse(inputs_all$h==1, 0.99, inputs_all$h)
LB_pars@BinWidth <- inputs_all$binwidth
LB_lengths <- new("LB_lengths")
LB_lengths@LMids <- inputs_all$mids
LB_lengths@LData <- t(matrix(inputs_all$LF, ncol=length(inputs_all$mids)))
LB_lengths@Years <- as.numeric(rownames(inputs_all$LF))
LB_lengths@NYears <- ncol(LB_lengths@LData)
lbspr <- LBSPRfit(LB_pars=LB_pars, LB_lengths=LB_lengths)
## plot length composition data
plot_LCfits(Inputs=Inputs,
Report=Report,
LBSPR=lbspr)
## plot model output
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
True=true,
LBSPR=lbspr,
plot=c("Fish","Rec","SPR","ML","SB","Selex"),
set_ylim=list("Fish" =c(0,1), "SPR" = c(0,1), "SB"=c(0,2)))
plot_output(Inputs=Inputs,
Report=Report,
Sdreport=Sdreport,
lh=lh,
True=true,
LBSPR=lbspr,
plot=c("Selex"),
set_ylim=list("Fish" =c(0,1), "SPR" = c(0,1), "SB"=c(0,2)))
setwd("~/Documents/Coding/R/R_analytics/fraud")
#===================
## Load Libraries
#===================
rm(list = ls()) #clear environment
packages <- c('ggplot2', 'corrplot','tidyverse',"caret","dummies","fastDummies"
,'FactoMineR','factoextra','readxl','scales','dplyr','mlbench','caTools',
'gridExtra','doParallel')
# load packages
for (package in packages) {
if (!require(package, character.only=T, quietly=T)) {
install.packages(package)
library(package, character.only=T)
}
}
# load data
df <- read.csv("FraudData.csv")
View(df)
missing_data <- apply(df, 2, function(x) any(is.na(x)))
print(missing_data)
#Label Encoder
labelEncoder <-function(x){
as.numeric(factor(x))-1
}
#normalize data
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# CHECK FOR IMBLANANCE
table(df$fraud)
df_cts <- df %>%
select(X, amount, age)
df_cat <- df %>%
select(category, gender, city, state)
df_fraud <- df %>%
select(fraud)
#combine data
df_cts <- as.data.frame(lapply(df_cts, normalize))
df_cat <- as.data.frame(lapply(cdf_cat, labelEncoder))
df_new <- cbind(df_cts,df_cat,df_fraud)
df_cts <- df %>%
select(X, amount, age)
df_cat <- df %>%
select(category, gender, city, state)
df_fraud <- df %>%
select(fraud)
#combine data
df_cts <- as.data.frame(lapply(df_cts, normalize))
df_cat <- as.data.frame(lapply(df_cat, labelEncoder))
df_new <- cbind(df_cts,df_cat,df_fraud)
#create train and test data
set.seed(2021)
sample <- sample.split(df_new,SplitRatio = 0.75)
train <- subset(df_new,sample ==TRUE)
test <- subset(df_new, sample==FALSE)
#model training
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
View(train)
model_weights <- ifelse(train$fraud == 0,
(1/table(train$fraud)[1]) * 0.5,
(1/table(train$fraud)[2]) * 0.5)
# cross fold validation
control <- trainControl(method="repeatedcv", number=10, repeats=5, classProbs = FALSE)
# cross fold validation
control <- trainControl(method="repeatedcv", number=10, repeats=5, classProbs = FALSE)
# #glm
fit.glm <- train(as.factor(fraud)~., data=train, method="glm",family=binomial(),
metric = "Accuracy", trControl = control, weights = model_weights)
#random forest
fit.rf <- train(as.factor(fraud)~., data=train, method="rf",
metric = "Accuracy", trControl = control, weights = model_weights)
#===================
# Fraud classification
#===================
rm(list = ls()) #clear environment
packages <- c('ggplot2', 'corrplot','tidyverse',"caret","dummies","fastDummies"
,'FactoMineR','factoextra','readxl','scales','dplyr','mlbench','caTools',
'gridExtra','doParallel','grid')
# load packages
for (package in packages) {
if (!require(package, character.only=T, quietly=T)) {
install.packages(package)
library(package, character.only=T)
}
}
fit.glm <- train(as.factor(fraud)~., data=train, method="glm",family=binomial(),
metric = "Accuracy", trControl = control, weights = model_weights)
# load data
df <- read.csv("FraudData.csv")
#back up
df.backup <- df
#===================
# Understand data
#===================
glimpse(df)
summary(df)
#look for missing data
missing_data <- apply(df, 2, function(x) any(is.na(x)))
print(missing_data)
#Label Encoder
labelEncoder <-function(x){
as.numeric(factor(x))-1
}
#normalize data
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# CHECK FOR IMBLANANCE
table(df$fraud)
df_cts <- df %>%
select(X, amount, age)
df_cat <- df %>%
select(category, gender, city, state)
df_fraud <- df %>%
select(fraud)
#combine data
df_cts <- as.data.frame(lapply(df_cts, normalize))
df_cat <- as.data.frame(lapply(df_cat, labelEncoder))
df_new <- cbind(df_cts,df_cat,df_fraud)
#create train and test data
set.seed(2021)
sample <- sample.split(df_new,SplitRatio = 0.75)
train <- subset(df_new,sample ==TRUE)
test <- subset(df_new, sample==FALSE)
#model training
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
model_weights <- ifelse(train$fraud == 0,
(1/table(train$fraud)[1]) * 0.5,
(1/table(train$fraud)[2]) * 0.5)
# cross fold validation
control <- trainControl(method="repeatedcv", number=10, repeats=5, classProbs = FALSE)
#random forest
fit.rf <- train(as.factor(fraud)~., data=train, method="rf",
metric = "Accuracy", trControl = control, weights = model_weights)
install.packages("e1071")
fit.glm <- train(as.factor(fraud)~., data=train, method="glm",family=binomial(),
metric = "Accuracy", trControl = control, weights = model_weights)
#random forest
fit.rf <- train(as.factor(fraud)~., data=train, method="rf",
metric = "Accuracy", trControl = control, weights = model_weights)
#boosting algorithm - Stochastic Gradient Boosting (Generalized Boosted Modeling)
fit.gbm <- train(as.factor(fraud)~., data=train, method="gbm",
metric = "Accuracy", trControl = control, weights = model_weights)
fit.gbm <- train(as.factor(fraud)~., data=train, method="gbm",
metric = "Accuracy", trControl = control, weights = model_weights)
#svm
fit.svm <- train(as.factor(fraud)~., data=train, method="svmRadial",
metric = "Accuracy", trControl = control, weights = model_weights)
#nnet
fit.nnet <- train(as.factor(fraud)~., data=train, method="nnet",
metric = "Accuracy", trControl = control, weights = model_weights)
fit.naive <- train(as.factor(fraud)~., data=train,
method="naive_bayes", metric = "Accuracy",
trControl = control, weights = model_weights)
#extreme gradient boosting
fit.xgb <- train(as.factor(fraud)~., data=train,
method="xgbTree", metric = "Accuracy",
trControl = control, weights = model_weights)
#bagged cart
fit.bg <- train(as.factor(fraud)~., data=train,
method="treebag", metric = "Accuracy",
trControl = control, weights = model_weights)
#decision tree
fit.dtree <- train(as.factor(fraud)~., data=train,
method="C5.0", metric = "Accuracy",
trControl = control, weights = model_weights)
#ensemble
fit.ensemble <- train(as.factor(fraud)~., data=train,
method="nodeHarvest", metric = "Accuracy",
trControl = control, weights = model_weights)
results <- resamples(list(randomforest = fit.rf,
`gradient boost` = fit.gbm,
`support vector machine` = fit.svm,
baggedCart = fit.bg,
neuralnetwork = fit.nnet,
xgboost = fit.xgb,
logisticregression = fit.glm,
`decision tree` = fit.dtree,
`naive bayes` = fit.naive,
#`ensemble` = fit.ensemble,
`knn` = fit.knn))
results <- resamples(list(randomforest = fit.rf,
`gradient boost` = fit.gbm,
`support vector machine` = fit.svm,
baggedCart = fit.bg,
neuralnetwork = fit.nnet,
xgboost = fit.xgb,
logisticregression = fit.glm,
# `decision tree` = fit.dtree,
`naive bayes` = fit.naive,
#`ensemble` = fit.ensemble,
`knn` = fit.knn))
results <- resamples(list(randomforest = fit.rf,
`gradient boost` = fit.gbm,
`support vector machine` = fit.svm,
baggedCart = fit.bg,
neuralnetwork = fit.nnet,
xgboost = fit.xgb,
logisticregression = fit.glm,
# `decision tree` = fit.dtree,
`naive bayes` = fit.naive,
#`ensemble` = fit.ensemble,
#`knn` = fit.knn
))
results <- resamples(list(randomforest = fit.rf,
`gradient boost` = fit.gbm,
`support vector machine` = fit.svm,
baggedCart = fit.bg,
neuralnetwork = fit.nnet,
xgboost = fit.xgb,
logisticregression = fit.glm,
# `decision tree` = fit.dtree,
`naive bayes` = fit.naive
#`ensemble` = fit.ensemble,
#`knn` = fit.knn
))
summary(results)
# boxplot comparison
bwplot(results)
# Dot-plot comparison
dotplot(results)
mean(predicted.classes == test$fraud)
mean(predicted.classes == test$fraud)
predicted.classes <- fit.xgb %>% predict(test)
output <- confusionMatrix(data = predicted.classes, reference = test$fraud, mode = "everything")
output
View(test)
output <- confusionMatrix(data = predicted.classes, reference = test$fraud, mode = "everything")
predicted.classes <- fit.xgb %>% predict(test)
View(test)
glimpse(test)
glimpse(train)
glimpse(predicted.classes)
output <- confusionMatrix(data = predicted.classes, reference = as.factor(test$fraud), mode = "everything")
output
caret::varImp(fit.xgb)
output2 <- as.data.frame(output$table)
colnames(output2) <- c("Predicted",'Actual',"Freq")
cm_d_p <-  ggplot(data =output2, aes(x = Predicted , y =  Actual, fill = Freq))+
geom_tile() +
geom_text(aes(label = paste("",Freq)), color = 'white', size = 8) +
theme_light() +
guides(fill=FALSE)
cm_d_p
#other metrics
caret::varImp(fit.xgb)
